import {A} from "@solidjs/router";
import { ToolsGallery } from "~/components/Gallery";

<main class="m-2">

<div class="m-2 mdx-content">

# Tools

<ToolsGallery />

## Motivations

I’ve never been a picky UI person. 

I worked with a lot of people who have this great eye for noting everything wrong in some kind of layout. 

I was more like the person who fixes them because I built the layout system. 

Technique interests me the most. I like making tools, trying to build core components with simple but flexible APIs, improving workflows, and chasing those little DX wins that make life easier. 

If it makes my future self’s day less painful, it’s worth the deep dive.

## Tools I Built

The most notable tools I made are:

1. All the tooling I made in Unreal which I'll try to post in a gallery here. Stuff like asset creation, editor extension points, some windows made in slate to debug some stuff with triggers and events, etc.
   1. Asset creation helpers let us fill out forms and create blueprints of the correct C++ base and sets up some boilerplate for asset types as well as creating data assets for the content's associated static data.
   2. Created many component visualizers including stuff to debug spawners, and stuff to debug actors in the game that spawn only when certain event flags are met.
   3. Added editor extension points for setting the camera bounds and camera start point associated with a level script, since in this game you need to set the camera to a starting point and also setup how much you can pan the camera for in each level.
   4. Added customized details panels for certain object types. This helps organize filling out data that's more like an intricate form (e.g., quests).
   5. Created custom tracks in the sequencer to show/hide the dialog box in tandem with sequence timings and VO.
   6. Created menus to debug units in the world include testing out their passive/aggressive AI modes and print out information about their behavior tree states and action states.
   7. Created a custom slate widget to debug information about all the triggers in the world.
2. *UpGPTNoiseFilter* which was my app I made to be a faster frontend for ChatGPT with some special features for storywriting like being the app parsing a story written in a specific markdown note format and helping you generate keywords which you can reuse in your prompts. The app would optimize not resending the entire summaries associated with keywords unless those summaries fall outside the context window.
   1. Code is located [here](https://gitlab.com/uperception/upgpt-noise-filter) but I haven't used int a while. Pretty sure it still works you just need to setup your own .env file and update the backend since the ChatGPT API endpoint might've changed.
3. *UpVoiceGenerator* - my more recent tool which is a script that parses my markdown story scripts and extracts the speaker, text, and then some context to map it to a voice prompt file. Then we use that as input to the [Chatterbox](https://github.com/resemble-ai/chatterbox) Python library to generate some voices for lines of dialog.
   1. We also have a custom track I made in Unreal which is designed to handle playing the VO tracks and controlling the visibility of the dialog box that shows the dialog text. The custom track also has some utility to parse the .wav files in a folder nested in the sequence to generate sections in my custom track and resize them based on the .wav duration.
4. My old dialog tool (code [here](https://github.com/cyphina/DialogTool)). Made in WPF and C#. I stopped using it cause I eventually integrated [https://github.com/NotYetGames/DlgSystem](this dialog tool).

Here's a video I made that has an overview of some of the tools I made.

<iframe
  width="560"
  height="315"
  src="https://www.youtube.com/embed/-jNzbmpEU8A?si=CIAtMFSpXQMimYEY"
  title="YouTube video player"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
  referrerpolicy="strict-origin-when-cross-origin"
  allowfullscreen
></iframe>

Here are a list of some of tools I made:

1. All the tooling I made in Unreal which I'll try to post in a gallery here. Stuff like asset creation, editor extension points, some windows made in slate to debug some stuff with triggers and events, etc. Some videos can be found on <A href="../Technical Docs/uimanagement">this page</A>.
   1. Asset creation helpers let us fill out forms and create blueprints of the correct C++ base and sets up some boilerplate for asset types as well as creating data assets for the content's associated static data.
   2. Created many component visualizers including stuff to debug spawners, and stuff to debug actors in the game that spawn only when certain event flags are met.
   3. Added editor extension points for setting the camera bounds and camera start point associated with a level script, since in this game you need to set the camera to a starting point and also setup how much you can pan the camera for in each level.
   4. Added customized details panels for certain object types. This helps organize filling out data that's more like an intricate form (e.g., quests).
   5. Created custom tracks in the sequencer to show/hide the dialog box in tandem with sequence timings and VO.
   6. Created menus to debug units in the world include testing out their passive/aggressive AI modes and print out information about their behavior tree states and action states.

<video width="100%" controls>
  <source src="SpawnerAndUnitInWorldDebugger.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>

   7. Created a custom slate widget to debug information about all the triggers in the world.
   8. Extended existing tool plugins like [NotYet's Dialog Plugin tool](https://github.com/NotYetGames/DlgSystem) with some QOL features like automatically creating nodes and links from pasting markdown code. 
2. *UpGPTNoiseFilter* which was my app I made to be a faster frontend for ChatGPT with some special features for storywriting like being the app parsing a story written in a specific markdown note format and helping you generate keywords which you can reuse in your prompts. The app would optimize not resending the entire summaries associated with keywords unless those summaries fall outside the context window.
   1. Code is located [here](https://gitlab.com/uperception/upgpt-noise-filter) but I haven't used int a while. Pretty sure it still works you just need to setup your own .env file and update the backend since the ChatGPT API endpoint might've changed.
   2. Made a technical document and video about its creation <A href="/Technical Docs/upgptnoisefilter">here</A>.
3. *UpVoiceGenerator* - my more recent tool which is a script that parses my markdown story scripts and extracts the speaker, text, and then some context to map it to a voice prompt file. Then we use that as input to the [Chatterbox](https://github.com/resemble-ai/chatterbox) Python library to generate some voices for lines of dialog.  
   1. We also have a custom track I made in Unreal which is designed to handle playing the VO tracks and controlling the visibility of the dialog box that shows the dialog text. The custom track also has some utility to parse the .wav files in a folder nested in the sequence to generate sections in my custom track and resize them based on the .wav duration.

<video width="100%" controls>
  <source src="CutscenePipelineExample.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>

4. My old dialog tool (code [here](https://github.com/cyphina/DialogTool)). Made in WPF and C#. I stopped using it cause I eventually integrated [https://github.com/NotYetGames/DlgSystem](this dialog tool).

</div>
</main>
